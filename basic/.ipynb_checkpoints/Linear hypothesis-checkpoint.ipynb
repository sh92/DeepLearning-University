{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"./magic.csv\", delimiter=\",\", dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15216.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)*4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(len(data)*4/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:idx]\n",
    "test_data = data[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = train_data[:, 0:-1]\n",
    "train_data_y = train_data[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = test_data[:, 0:-1]\n",
    "test_data_y = test_data[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15216, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15216, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([10, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 0  cost:  0.384392 \n",
      "Accuracy:  0.693283\n",
      "Steps 100  cost:  0.21581 \n",
      "Accuracy:  0.734293\n",
      "Steps 200  cost:  0.20999 \n",
      "Accuracy:  0.737119\n",
      "Steps 300  cost:  0.205616 \n",
      "Accuracy:  0.739945\n",
      "Steps 400  cost:  0.202207 \n",
      "Accuracy:  0.741193\n",
      "Steps 500  cost:  0.199455 \n",
      "Accuracy:  0.740865\n",
      "Steps 600  cost:  0.197159 \n",
      "Accuracy:  0.740668\n",
      "Steps 700  cost:  0.195186 \n",
      "Accuracy:  0.740273\n",
      "Steps 800  cost:  0.193449 \n",
      "Accuracy:  0.741588\n",
      "Steps 900  cost:  0.191889 \n",
      "Accuracy:  0.741719\n",
      "Steps 1000  cost:  0.190468 \n",
      "Accuracy:  0.742245\n",
      "Steps 1100  cost:  0.189157 \n",
      "Accuracy:  0.743165\n",
      "Steps 1200  cost:  0.187938 \n",
      "Accuracy:  0.744085\n",
      "Steps 1300  cost:  0.186797 \n",
      "Accuracy:  0.744019\n",
      "Steps 1400  cost:  0.185725 \n",
      "Accuracy:  0.744808\n",
      "Steps 1500  cost:  0.184714 \n",
      "Accuracy:  0.7454\n",
      "Steps 1600  cost:  0.183758 \n",
      "Accuracy:  0.746583\n",
      "Steps 1700  cost:  0.182852 \n",
      "Accuracy:  0.747963\n",
      "Steps 1800  cost:  0.181993 \n",
      "Accuracy:  0.749146\n",
      "Steps 1900  cost:  0.181175 \n",
      "Accuracy:  0.750263\n",
      "Steps 2000  cost:  0.180398 \n",
      "Accuracy:  0.751446\n",
      "Steps 2100  cost:  0.179657 \n",
      "Accuracy:  0.751709\n",
      "Steps 2200  cost:  0.178952 \n",
      "Accuracy:  0.752366\n",
      "Steps 2300  cost:  0.178278 \n",
      "Accuracy:  0.753417\n",
      "Steps 2400  cost:  0.177635 \n",
      "Accuracy:  0.754075\n",
      "Steps 2500  cost:  0.17702 \n",
      "Accuracy:  0.753746\n",
      "Steps 2600  cost:  0.176433 \n",
      "Accuracy:  0.75414\n",
      "Steps 2700  cost:  0.17587 \n",
      "Accuracy:  0.754272\n",
      "Steps 2800  cost:  0.175331 \n",
      "Accuracy:  0.754732\n",
      "Steps 2900  cost:  0.174815 \n",
      "Accuracy:  0.754863\n",
      "Steps 3000  cost:  0.17432 \n",
      "Accuracy:  0.754929\n",
      "Steps 3100  cost:  0.173844 \n",
      "Accuracy:  0.75506\n",
      "Steps 3200  cost:  0.173387 \n",
      "Accuracy:  0.755849\n",
      "Steps 3300  cost:  0.172948 \n",
      "Accuracy:  0.756441\n",
      "Steps 3400  cost:  0.172526 \n",
      "Accuracy:  0.757098\n",
      "Steps 3500  cost:  0.17212 \n",
      "Accuracy:  0.757755\n",
      "Steps 3600  cost:  0.171728 \n",
      "Accuracy:  0.758281\n",
      "Steps 3700  cost:  0.171351 \n",
      "Accuracy:  0.758412\n",
      "Steps 3800  cost:  0.170987 \n",
      "Accuracy:  0.757952\n",
      "Steps 3900  cost:  0.170636 \n",
      "Accuracy:  0.758149\n",
      "Steps 4000  cost:  0.170297 \n",
      "Accuracy:  0.758149\n",
      "Steps 4100  cost:  0.169969 \n",
      "Accuracy:  0.758675\n",
      "Steps 4200  cost:  0.169653 \n",
      "Accuracy:  0.758741\n",
      "Steps 4300  cost:  0.169346 \n",
      "Accuracy:  0.759398\n",
      "Steps 4400  cost:  0.16905 \n",
      "Accuracy:  0.759858\n",
      "Steps 4500  cost:  0.168762 \n",
      "Accuracy:  0.760384\n",
      "Steps 4600  cost:  0.168484 \n",
      "Accuracy:  0.760384\n",
      "Steps 4700  cost:  0.168214 \n",
      "Accuracy:  0.760712\n",
      "Steps 4800  cost:  0.167952 \n",
      "Accuracy:  0.76091\n",
      "Steps 4900  cost:  0.167698 \n",
      "Accuracy:  0.761172\n",
      "Steps 5000  cost:  0.167451 \n",
      "Accuracy:  0.761633\n",
      "Steps 5100  cost:  0.167211 \n",
      "Accuracy:  0.761501\n",
      "Steps 5200  cost:  0.166977 \n",
      "Accuracy:  0.761895\n",
      "Steps 5300  cost:  0.16675 \n",
      "Accuracy:  0.762355\n",
      "Steps 5400  cost:  0.166529 \n",
      "Accuracy:  0.762684\n",
      "Steps 5500  cost:  0.166314 \n",
      "Accuracy:  0.76321\n",
      "Steps 5600  cost:  0.166105 \n",
      "Accuracy:  0.763604\n",
      "Steps 5700  cost:  0.165901 \n",
      "Accuracy:  0.763736\n",
      "Steps 5800  cost:  0.165702 \n",
      "Accuracy:  0.763801\n",
      "Steps 5900  cost:  0.165508 \n",
      "Accuracy:  0.764196\n",
      "Steps 6000  cost:  0.165318 \n",
      "Accuracy:  0.764524\n",
      "Steps 6100  cost:  0.165133 \n",
      "Accuracy:  0.76459\n",
      "Steps 6200  cost:  0.164953 \n",
      "Accuracy:  0.764853\n",
      "Steps 6300  cost:  0.164777 \n",
      "Accuracy:  0.765116\n",
      "Steps 6400  cost:  0.164605 \n",
      "Accuracy:  0.765444\n",
      "Steps 6500  cost:  0.164436 \n",
      "Accuracy:  0.76551\n",
      "Steps 6600  cost:  0.164272 \n",
      "Accuracy:  0.765707\n",
      "Steps 6700  cost:  0.164111 \n",
      "Accuracy:  0.765904\n",
      "Steps 6800  cost:  0.163953 \n",
      "Accuracy:  0.766299\n",
      "Steps 6900  cost:  0.163799 \n",
      "Accuracy:  0.766627\n",
      "Steps 7000  cost:  0.163648 \n",
      "Accuracy:  0.766824\n",
      "Steps 7100  cost:  0.1635 \n",
      "Accuracy:  0.767022\n",
      "Steps 7200  cost:  0.163355 \n",
      "Accuracy:  0.767153\n",
      "Steps 7300  cost:  0.163214 \n",
      "Accuracy:  0.767022\n",
      "Steps 7400  cost:  0.163074 \n",
      "Accuracy:  0.76735\n",
      "Steps 7500  cost:  0.162938 \n",
      "Accuracy:  0.767613\n",
      "Steps 7600  cost:  0.162805 \n",
      "Accuracy:  0.767482\n",
      "Steps 7700  cost:  0.162674 \n",
      "Accuracy:  0.767613\n",
      "Steps 7800  cost:  0.162545 \n",
      "Accuracy:  0.767744\n",
      "Steps 7900  cost:  0.162419 \n",
      "Accuracy:  0.767876\n",
      "Steps 8000  cost:  0.162295 \n",
      "Accuracy:  0.768205\n",
      "Steps 8100  cost:  0.162173 \n",
      "Accuracy:  0.768336\n",
      "Steps 8200  cost:  0.162054 \n",
      "Accuracy:  0.768467\n",
      "Steps 8300  cost:  0.161937 \n",
      "Accuracy:  0.76873\n",
      "Steps 8400  cost:  0.161822 \n",
      "Accuracy:  0.768862\n",
      "Steps 8500  cost:  0.161709 \n",
      "Accuracy:  0.768993\n",
      "Steps 8600  cost:  0.161597 \n",
      "Accuracy:  0.769059\n",
      "Steps 8700  cost:  0.161488 \n",
      "Accuracy:  0.76919\n",
      "Steps 8800  cost:  0.161381 \n",
      "Accuracy:  0.769322\n",
      "Steps 8900  cost:  0.161275 \n",
      "Accuracy:  0.769585\n",
      "Steps 9000  cost:  0.161171 \n",
      "Accuracy:  0.769716\n",
      "Steps 9100  cost:  0.161069 \n",
      "Accuracy:  0.769848\n",
      "Steps 9200  cost:  0.160969 \n",
      "Accuracy:  0.77011\n",
      "Steps 9300  cost:  0.16087 \n",
      "Accuracy:  0.77011\n",
      "Steps 9400  cost:  0.160773 \n",
      "Accuracy:  0.770242\n",
      "Steps 9500  cost:  0.160678 \n",
      "Accuracy:  0.770636\n",
      "Steps 9600  cost:  0.160584 \n",
      "Accuracy:  0.770899\n",
      "Steps 9700  cost:  0.160491 \n",
      "Accuracy:  0.771096\n",
      "Steps 9800  cost:  0.1604 \n",
      "Accuracy:  0.770965\n",
      "Steps 9900  cost:  0.16031 \n",
      "Accuracy:  0.770965\n",
      "Steps 10000  cost:  0.160222 \n",
      "Accuracy:  0.77103\n",
      "\n",
      "#### Test ####\n",
      "\n",
      "Hypothesis:  [[ 0.30453843]\n",
      " [ 0.82419336]\n",
      " [ 0.33769846]\n",
      " ..., \n",
      " [ 0.19512197]\n",
      " [ 0.17329927]\n",
      " [ 0.66722292]] \n",
      "Correct (Y):  [[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " ..., \n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]] \n",
      "Accuracy:  0.761567\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlBkYfdgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117809d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_list=[]\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed = {X: train_data_x, Y: train_data_y}\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict=feed) \n",
    "        if step % 100 == 0:\n",
    "            c, a = sess.run([cost , accuracy], feed_dict=feed)\n",
    "            print(\"Steps\", step, \" cost: \", c, \"\\nAccuracy: \", a)\n",
    "            cost_list.append(c)\n",
    "    print(\"\")\n",
    "    print(\"#### Test ####\")\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:test_data_x, Y:test_data_y})\n",
    "    print(\"\\nAccuracy: \", a)\n",
    "    \n",
    "    plt.plot(cost_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
